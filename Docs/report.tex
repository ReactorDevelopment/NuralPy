\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[en-US,showdow=false]{datetime2}
\nocite{*}
\title{\bf{Predictive Diabetes Diagnosis using Backpropogation, 
Genetic Training, and Decision Tree Optimization}}
\author{
    Terranova, Joeseph\\
    \and
    Pisano, Matthew\\
}
\DTMlangsetup[en-GB]{ord=raise,monthyearsep={,\space}}

\DTMsavedate{date}{2022-03-17}
\date{\DTMusedate{date}}
\graphicspath{{./images/}}
\begin{document}
\maketitle

\section{Introduction}
    \subsection{Project Motivation}
        The motivation of this project originated from curiosity about the nature of neural 
        networks and the efficiency of the different methods used to train them.
    \subsection{Aims and Objectives}
        The objective of the project is to compare the methods of backpropogation, genetic 
        algorithms, and decision trees on their abilities to predict a positive diabetes diagnosis.  For
        this project, we based our results on a training set from the Vanderbilt University Department of Biostatistics.
    \subsection{Report Structure}
        The structure of this report will focus on the explanation and experimentation involving the
        different methods of training neural networks.  First, an explanation of the implementation of each technique
        will be described, the networks will then have their preformance measured and compared.  Conclusions will
        then be drawn.
\section{Background and History of the Study}
    Originally only concentrating on neural networks that utilize decision trees, 
    the scope of the project has grown to include the learning methods of backpropogation and 
    genetic algorithms as time has permitted.
    
    Neural networks produce results through the many interactions 
    between its neurons.  These neurons are organized in layers. The first layer is the input layer, 
    where data is first given to the network and the last layer is the output layer, which takes input 
    from other neurons and outputs the result of the network.  Between these layers are zero or more 
    hidden layers.  They function the similarly to the output layer, taking input from the layer before it 
    and producing an output.
    
    Since the introduction of the \textit{Perceptron} in 1958 and the many expansions upon its
    ideas since, many different methods and techniques have been developed to train Neural Networks.  The purpose of
    this study is to investigate the different advantages and drawbacks of the three chosen techniques.  
    Backpropogation is used for many applications
    including feature detection and handwriting recognition.  Genetic algorithms are less computationally intensive than backpropogation
    but can take longer over their many generations.  An advantage of genetic algorithms is their reliablility to converge on local or
    global minima.  Optimization with a decision tree adds extra efficency to a neural network.  By eliminating some input attributes, many calculations
    can be saved, especually with the matrix-heavy calculations of backpropogation.
\section{Implementation}
    The first steps to conducting the experiment were to craft each of the different neural networks.  The implementation
    of each network was conducted in Python \cite{python} with extensive use of the NumPy \cite{numPy} library for its light and efficent
    array and matrix implementations.
    \subsection{Backpropogation} 
        The backpropogation network was first, originally utilizing a graph data structure for its 
        implementation.  The network was first ordered by layers, with the nodes of the graph (neurons) 
        being organized by layer in arrays, with each node being connected to every node in the layer after it.  
        Nodes fired after all of the nodes connecting to it had already fired, with the output layer yielding a result right after the 
        input layer was set with a sample to train on.
        \begin{figure}[h]
            \includegraphics[scale=.3]{nnDiagram.png}
            \centering
            \caption{Example of a Neural Network \cite{nnDiagram}}
        \end{figure}

        Output from these neurons is produced by taking the sum of all its inputs (\(I_i\)), each multiplied by a weight (\(W_i\)), 
        and subtracting the neuron's bias (\(b\)).  The result of this summation is then passed into the activation function to produce 
        the final output of the neuron. The activation function scales the summation to be between zero and one.  
        The sigmoid (\(\sigma\)) function was used in this experiment. As shown in \cite{guideToIntSys},
        \begin{equation}\label{inputSum}
            Y = \sigma[\sum_{i=1}^{n} (I_i W_i) - b]
        \end{equation}

        One of the most popular methods of training neural networks is through backpropogation.  
        In this method, the network is fed how different each layer's output was from the correct output, 
        starting at the output layer and ending at the first hidden layer.

        The error between the expected output and the observed output (\(e\)) is calculated by taking their difference.
        The error gradient (\(\delta\)) of the neuron, used to calculate the change in each weight, is calculated by using a formula similar
        to \ref{inputSum} but using the derivative of \(\sigma\) instead of \(\sigma\) itself multiplied by the error (\(e\)).
        \begin{equation}\label{errGradient}
            \delta = \frac{d\sigma}{dx}[\sum_{i=1}^{n} (I_i W_i) - b] e
        \end{equation}
        The change for each weight (\(\Delta W_i\)) in the output nodes is calculated by multiplying the error gradient,
        a learning rate constant (\(\alpha\)), and the previous output (\(Y_p\)) of the node together.
        \begin{equation}\label{outputWeightDelta}
            \Delta Y = \delta \alpha Y_p
        \end{equation}
        For the hidden layers, then change in their weights are similar.  Instead of the error of the output nodes, however,
        the summation of each error gradient of the nodes in the previous layer (\(\delta_j\) for node \(j\) in the previous layer) 
        multiplied by their weights for the current node (\(W_j\)).
        \begin{equation}\label{hiddenWeightDelta}
            \delta = \frac{d\sigma}{dx}[\sum_{i=1}^{n} (I_i W_i) - b]*\sum_{j=1}^{n_p} (\delta_j W_j)
        \end{equation}
        When this process is repeated for many epochs over one data set, the output of the network becomes more
        tuned to the desired result.
    \subsection{Decision Tree Optimization}
        One of the drawbacks to a backpropogation neural network are its many matrix calculations.  For a network as small as the
        one being used here, the number of inputs can impact the speed at which calculations can be performed.  Using a decision tree,
        less useful attributes can be eliminated to cut down on the number of operations that the neural network executes.

        On its own, a decision tree can be a useful predictor of results, especially in the attribute-based data set that is being used here.
        A decision tree orders the attributes by their \textit{Entropy} and \textit{Information Gain}.  The entropy of the entire set is given by the negative 
        sum of proportion of each class out of the size of the sample \(\frac{c_i}{n}\) multiplied by the binary logarithm of that proportion. 
        \begin{equation}\label{totalEntropy}
            \mathcal{E} = -\sum_{i=1}^{n} (\frac{c_i}{n} log_2[\frac{c_i}{n}])
        \end{equation}
        The entropy of any given attribute is gotten similarly.
        The Entropy of an attribute measures how well a given attribute \(i\) where \(|A_i| = \frac{A_i}{n}\) is the proportion of samples where the attribute is true,
        \(|c_{jAi}| = \frac{c_{jAi}}{A_i}\) is the proportion of class \(j\) given \(A_i\) is true over the total number of samples where \(A_i\) is true,
        \(\neg|c_{jAi}| = \frac{c_{jAi}}{~A_i}\) is the proportion of class \(j\) given \(A_i\) is false over the total number of samples where \(A_i\) is false, 
        and \(|C|\) is the total number of classes.
        \begin{equation}\label{attribInfoGain}
            \mathcal{E}_i = -|A_i| \sum_{j=1}^{|C|} (|c_{jAi}| log_2[|c_{jAi}|]) - (\neg|A_i|) \sum_{j=1}^{|C|} (\neg|c_{jAi}| log_2[\neg|c_{jAi}|])
        \end{equation} 
        Information Gain is given by the entropy of the entire set minus the entropy of a given attribute.
        \begin{equation}\label{infoGain}
            gain(x) = \mathcal{E} - \mathcal{E}_i
        \end{equation} 
        Entropy measures how well an attribute or the whole set predicts the class the sample will belong to and the 
        Information Gain of an attribute measures how much lower the entropy of
        an attribute is when compared to the entire set.  This is useful for determining which attributes have the largest impact on the
        prediction of the classes in a sample set.  Utilizing this principle, we can only use the most consequential attributes for imputs to the
        neural network.
    \subsection{Genetic Algorithm}
        Genetic algorithms are quite different from backpropogation, utilizing trends within nature as inspiration.
        The training begins with a population of randomly generated individuals.  Each indivudual is composed of a genome which 
        describes every weight and bias of every neuron within a neural network.  Each gene within that genome represents
        the set of all weights (one from each node in layer \(i\)) relating to the connections of one node in layer \(i-1\).

        As the training begins, each member of the polulation has its fitness evaluated.  The evaluation function for this project
        is the reciprocal of the loss function, \(fitness(memberId) = \frac{1}{loss(memberId)}\).  Two parents from the population
        are then selected using the roulette wheel method, where parents are randomly chosen, biased twoard parents with high fittness scores.
        The genomes of the parents are crossed between two new children.  A point on the genome is randomly chosen (\(p\)) where
        child genes are composed of correcponding parent genes for the section up to \(p\) then composed of the oppisite parent after \(p\).
        \pagebreak
        \begin{figure}[h]
            \includegraphics[scale=.5]{crossover.png}
            \centering
            \caption{Illustration of crossover \cite{crossoverDiagram}}
        \end{figure}

        This ensures that there is a good mix between the characteristics of the parents passed down to the children.

        Each child may then undergo a mutation, where an individual gene is mutated to a random value.  This serves the
        purpose of guiding genes out of local maximums (genes that evolve to do well for a specific subset of samples, but
        not the samples as a whole).
        
        This cycle continues until the amount of children produces equals the size of the original population.  The population
        is then replaced with the children.  This represents on generation of the neural network.
        When this process is repeated for many epochs over one data set, the output of the network becomes more
        tuned to the desired result.
\section{Experimental Approach}
    \subsection{Data Set and Preparation}
        The data set used for this project is from the Vanderbilt University Department of Biostatics and contains
        the testing parameters and results of 390 African American participants from central Virginia \cite{diabetesData}.
        The parameters of the dataset are comprised of the patient's cholesterol, blood glucose levels, high-density lipoprotein (HDL)
        or "good" cholesterol, the ratio of HDL cholesterol to total cholesterol, age, gender, height, weight, body mass index (BMI),
        systolic blood pressure, and diastolic blood pressure.  The entries in the dataset are categorized into two groups, those that
        were diagnosed with diabestes and those who were not.

        Before usage in training, the data set was first normalized.  When a data set is normalized, all of its values are scaled
        between zero and one.  After normalization, the highest value in the data set is scaled near to 1 and the lowest is scaled near to zero.
        Normalization allows the neural net to only deal with smaller numbers without removing the relative scale of the original data.
        The next step was to then classifiy the data into diebetic and non-diabetic groups and then to split the data into training and
        testing sets using an 80:20 split.

        After normalizing the data points and classifying the samples, the data set is ready to be used in the neural network.
        For each data point, there where eleven attributes and the class, a positive or negative diagnosis.
        The input layer of each network therefore had eleven nodes.
        Hidden layers with 5 nodes or under resulted in low computation times, but no hidden layer at all performed the best across the various methods.
        For this data set, the ouptut layer has two nodes, representing the confidence that the given participant does or does not have diabetes.
\section{Training and Results}
    For training, each one of the three networks was given the same 80\% proportion of the original data set and trained for
        150 epochs and three independent trials.
    The loss function for each network is given by the sum of squared errors for every sample.
    \begin{equation}\label{sumSquaredErrs}
        loss = \sum_{i=1}^{n_{samples}} \sum_{j=1}^{n_{outputs}} (output_{ij} - expected_{ij})^2
    \end{equation}
    Each trial was given a score for comparrison.  The score is given by the percent of correctly identified diagnoses divided by the time it took for the
    trial to complete.  The higher the score, the better the preformance of the algorithm.
    \pagebreak
    
    For the backpropogation network, a learning rate (\(\alpha\)) of 0.18 was used.  Across three trials, training over the data set for
    the 150 epochs, the network trained after 0.82 seconds on average.  The average loss for the testing set was 0.125, 
    correctly predicting 85.9\% of diagnoses in the testing set and 95.1\% withing the training set, as shown below.
    Its overall score was 0.96.
    \begin{figure}[h]
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=.9\linewidth]{backproplosses.png}
            \caption{Loss value over successive epochs for backpropogation}
        \end{minipage}\hfill
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=.9\linewidth]{backpropaccuracy.png}
            \caption{Diagnosis accuracy over successive training set epochs for backpropogation}
        \end{minipage}
    \end{figure}

    The training loss curve for backpropogation follows closely to a curve of \(\frac{1}{x}\).  This signifies a good loss curve with minimal
    overfitting \cite{goodLoss}.  The loss declines sharply and the accuracy rises rapidly over successive epochs of training.
    \pagebreak

    For the backpropogation network with the decision tree optimization, a learning rate (\(\alpha\)) of 0.18 was used.  Across three trials, training over the data set for
    the 150 epochs, the network trained after 0.78 seconds on average.  The average loss for the testing set was 0.125, 
    correctly predicting 84.2\% of diagnoses in the testing set and 95.0\% withing the training set, as shown below.
    Its overall score was 1.05.
    \begin{figure}[h]
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=.9\linewidth]{decisionlosses.png}
            \caption{Loss value over successive epochs for backpropogation}
        \end{minipage}\hfill
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=.9\linewidth]{decisionaccuracy.png}
            \caption{Diagnosis accuracy over successive training set epochs for backpropogation}
        \end{minipage}
    \end{figure}

    The training loss curve for optimized backpropogation follows closely to a curve of \(\frac{1}{x}\).  This signifies a good loss curve with minimal
    overfitting \cite{goodLoss}.  The loss declines sharply and the accuracy rises rapidly over successive epochs of training.

    For the genetic algorithm, a population size of 6, a crossover rate of 0.5, and a mutation rate of 0.01.  Across three trials, the network
    took 4.95 seconds.  The avarage loss for the testing set was 0.295, correctly identifying 70.4\% of diagnoses in the testing set and 88.1\% withing the training set, as shown below.
    Its overall score was 0.138.
    
    \begin{figure}[h]
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=.9\linewidth]{geneticlosses.png}
            \caption{Loss value over successive epochs for the genetic algorithm}
        \end{minipage}\hfill
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=.9\linewidth]{geneticaccuracy.png}
            \caption{Diagnosis accuracy over successive training set epochs for the genetic algorithm}
        \end{minipage}
    \end{figure}
    
    \pagebreak

    The training loss curve for the genetic algorithm shows a less pronounced curve, correcponding well with a high
    learning rate and a high change of over-fitting \cite{goodLoss}.  The loss of the algorithm dropped sharply after the 
    training started but leveled out higher than
    backpropogation did, resulting in a high accuracy, but it did not improve significantly over time.
\section{Conclusions}
    Across the three trials for the three different algorithms, Backpropogation with the decision tree optimization
    seems to be the best fit for this particular data set.  It completed quickly and with a high accuracy of 84.2\% 
    and score of 1.05 when predicting if a subject was diagnosed with diabetes given their medical attributes.  

    One of the drawbacks of the genetic algorithm, as opposed to
    backpropogation, was its tendency to settle into local minima in addition to its slow speed.  Often, the genetic algorithm would converge
    on a solution that was better than chance, but sub optimal.  Backpropogation more often converged on a more optimal colution
    than the genetic algorithm.  Backpropogation was also much faster, due in large part to the efficiencies of NumPy
    arrays.  The optimization of NumPy arrays is focused on multiplication, due to the genetic algorithm having less array multiplication,
    it was not able to leverage the advantages of the arrays as much as backpropogation, resulting in a slower algorithm.

\pagebreak
\bibliographystyle{plain}
\bibliography{refs}
\end{document}